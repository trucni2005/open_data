{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apify_client import ApifyClient\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ApifyClient(\"apify_api_LJB3wsOd9H1iYEdfnBflCoSc8nO9GG0zX6TS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_googlesearch_by_apify(input, client, num, time_now):\n",
    "    \n",
    "    \n",
    "    run_input = {\n",
    "        \"queries\": f\"{input}\",\n",
    "        \"lang\": \"vi\",\n",
    "        \"maxPagesPerQuery\": math.ceil(int(num+30)/10),\n",
    "        \"resultsPerPage\": 10,\n",
    "        \"countryCode\": \"\",\n",
    "        \"customDataFunction\": \"\"\"async ({ input, $, request, response, html }) => {\n",
    "            return {\n",
    "                pageTitle: $('title').text(),\n",
    "            };\n",
    "        };\"\"\",\n",
    "    }\n",
    "\n",
    "    run = client.actor(\"apify/google-search-scraper\").call(run_input=run_input)\n",
    "\n",
    "    results = []\n",
    "    for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "        results.append(item)\n",
    "\n",
    "    with open(f\"data/googlesearch/{time_now}_{input}_apify.json\", \"w\") as file:\n",
    "        json.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_googlesearch_by_selenium(key, num_results, time_now):\n",
    "    key = key.replace(\" \", \"+\")\n",
    "    filename = f'./data/googlesearch/{time_now}_{key}_selenium.csv'\n",
    "\n",
    "    fields = ['title', 'link', 'description']\n",
    "    driver = webdriver.Chrome()\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
    "        writer.writeheader()\n",
    "        result = 0\n",
    "        for i in range(math.ceil((num_results + 50) / 10)):\n",
    "            link = f'https://www.google.com/search?q={key}&start={i*10}'\n",
    "            driver.get(link)\n",
    "            driver.implicitly_wait(5)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            h3_tags = soup.find_all('h3', class_='LC20lb MBeuO DKV0Md')\n",
    "            divs = soup.find_all('div', class_='yuRUbf')\n",
    "            div_des = soup.find_all('div', class_='VwiC3b yXK7lf MUxGbd yDYNvb lyLwlc lEBKkf')\n",
    "            for h3_tag, div, div_des in zip(h3_tags, divs, div_des):\n",
    "                title = h3_tag.text\n",
    "                a_tag = div.find('a')\n",
    "                href = a_tag.get('href')\n",
    "                descriptions = div_des.find_all('span')\n",
    "                description = ''\n",
    "                for des in descriptions:\n",
    "                    description = description+ des.text\n",
    "                writer.writerow({'title': title, 'link': href, 'description' : description})\n",
    "                result += 1\n",
    "                if result == num_results:\n",
    "                    break\n",
    "            if result == num_results:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to search 66 results by apify: 16.039082765579224\n",
      "Time to search 66 results by selenium: 14.865723371505737\n"
     ]
    }
   ],
   "source": [
    "key = input(\"Nhập từ khóa bạn muốn tìm kiếm: \")\n",
    "num_results = int(input(\"Nhập số lượng bài viết bạn muốn tìm kiếm: \"))\n",
    "current_time = datetime.datetime.now()\n",
    "time_now = current_time.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "start_time = time.time()\n",
    "crawl_googlesearch_by_apify(key, client, num_results, time_now)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time to search {num_results} results by apify: {elapsed_time}\")\n",
    "start_time = time.time()\n",
    "crawl_googlesearch_by_selenium(key, num_results, time_now)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time to search {num_results} results by selenium: {elapsed_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
